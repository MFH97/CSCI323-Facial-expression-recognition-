# -*- coding: utf-8 -*-
"""323 group project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YwNYAJpVZJSrtcq44f5ahijeoWCVFM8e

Facial Expression Recognition

Mount the dataset from google drive
"""

from google.colab import drive
drive.mount('/content/drive')



"""Load and Pre process"""

import os
import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator

base_dir = '/content/drive/MyDrive/Assignment/train'
img_size = (224, 224)  # Size for VGG and ResNet input

datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

train_generator = datagen.flow_from_directory(
    base_dir,
    target_size=img_size,
    batch_size=32,
    class_mode='categorical',
    subset='training'
)

validation_generator = datagen.flow_from_directory(
    base_dir,
    target_size=img_size,
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)

"""Model Training

a.CNN
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

def create_cnn_model():
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
        MaxPooling2D((2, 2)),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Flatten(),
        Dense(512, activation='relu'),
        Dropout(0.5),
        Dense(7, activation='softmax')  # Assuming 7 classes
    ])
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

cnn_model = create_cnn_model()
cnn_model.summary()

cnn_model.fit(train_generator, validation_data=validation_generator, epochs=10)

"""b. VGG16"""

from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import GlobalAveragePooling2D

def create_vgg_model():
    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
    model = Sequential([
        base_model,
        GlobalAveragePooling2D(),
        Dense(512, activation='relu'),
        Dropout(0.5),
        Dense(7, activation='softmax')
    ])
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

vgg_model = create_vgg_model()
vgg_model.summary()

vgg_model.fit(train_generator, validation_data=validation_generator, epochs=10)

"""C. ResNut50"""

from tensorflow.keras.applications import ResNet50

def create_resnet_model():
    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
    model = Sequential([
        base_model,
        GlobalAveragePooling2D(),
        Dense(512, activation='relu'),
        Dropout(0.5),
        Dense(7, activation='softmax')
    ])
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

resnet_model = create_resnet_model()
resnet_model.summary()

resnet_model.fit(train_generator, validation_data=validation_generator, epochs=10)

"""Model Evaluation"""

from sklearn.metrics import classification_report, confusion_matrix

def evaluate_model(model, validation_generator):
    Y_pred = model.predict(validation_generator)
    y_pred = np.argmax(Y_pred, axis=1)
    print('Confusion Matrix')
    print(confusion_matrix(validation_generator.classes, y_pred))
    print('Classification Report')
    target_names = list(validation_generator.class_indices.keys())
    print(classification_report(validation_generator.classes, y_pred, target_names=target_names))

evaluate_model(cnn_model, validation_generator)
evaluate_model(vgg_model, validation_generator)
evaluate_model(resnet_model, validation_generator)

"""Predict Expression and Choose the image

a. CNN
"""

import numpy as np
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from google.colab import files

# Function to load and preprocess the image
def load_and_preprocess_image(img_path):
    img = image.load_img(img_path, target_size=(48, 48))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
    img_array /= 255.0  # Rescale to [0, 1]
    return img_array

# Function to predict the class of the image
def predict_emotion(img_path, model):
    class_labels = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']
    img_array = load_and_preprocess_image(img_path)
    predictions = model.predict(img_array)
    predicted_class = np.argmax(predictions)
    return class_labels[predicted_class]

# Upload and predict
uploaded = files.upload()

for img_path in uploaded.keys():
    # Display the image
    img = mpimg.imread(img_path)
    plt.imshow(img)
    plt.axis('off')
    plt.show()

    # Predict the emotion
    predicted_emotion = predict_emotion(img_path, cnn_model )  # Replace `model` with the specific model variable
    print(f'The predicted emotion for {img_path} is: {predicted_emotion}')

"""b. VGG16"""

import numpy as np
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from google.colab import files

# Function to load and preprocess the image
def load_and_preprocess_image(img_path):
    img = image.load_img(img_path, target_size=(48, 48))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
    img_array /= 255.0  # Rescale to [0, 1]
    return img_array

# Function to predict the class of the image
def predict_emotion(img_path, model):
    class_labels = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']
    img_array = load_and_preprocess_image(img_path)
    predictions = model.predict(img_array)
    predicted_class = np.argmax(predictions)
    return class_labels[predicted_class]

# Upload and predict
uploaded = files.upload()

for img_path in uploaded.keys():
    # Display the image
    img = mpimg.imread(img_path)
    plt.imshow(img)
    plt.axis('off')
    plt.show()

    # Predict the emotion
    predicted_emotion = predict_emotion(img_path, vgg_model )  # Replace `model` with the specific model variable
    print(f'The predicted emotion for {img_path} is: {predicted_emotion}')

"""C. ResNut"""

import numpy as np
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from google.colab import files

# Function to load and preprocess the image
def load_and_preprocess_image(img_path):
    img = image.load_img(img_path, target_size=(48, 48))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
    img_array /= 255.0  # Rescale to [0, 1]
    return img_array

# Function to predict the class of the image
def predict_emotion(img_path, model):
    class_labels = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']
    img_array = load_and_preprocess_image(img_path)
    predictions = model.predict(img_array)
    predicted_class = np.argmax(predictions)
    return class_labels[predicted_class]

# Upload and predict
uploaded = files.upload()

for img_path in uploaded.keys():
    # Display the image
    img = mpimg.imread(img_path)
    plt.imshow(img)
    plt.axis('off')
    plt.show()

    # Predict the emotion
    predicted_emotion = predict_emotion(img_path, resnet_model )  # Replace `model` with the specific model variable
    print(f'The predicted emotion for {img_path} is: {predicted_emotion}')